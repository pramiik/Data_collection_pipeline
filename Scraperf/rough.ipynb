{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = Chrome()\n",
    "driver.get('https://www.goodreads.com/')\n",
    "\n",
    "\n",
    "'''\n",
    "search_bar = driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[1]/div[1]/div[2]/div[4]/div[1]/div/div[2]/form/div/input')\n",
    "\n",
    "search_bar.click()\n",
    "search_bar.send_keys('stephen king')\n",
    "\n",
    "search = driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[1]/div[1]/div[2]/div[4]/div[1]/div/div[2]/form/a/img')\n",
    "search.click()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "        \n",
    "        search_bar = self.driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[1]/div[1]/div[2]/div[4]/div[1]/div/div[2]/form/div/input')\n",
    "\n",
    "        search_bar.click()\n",
    "        search_bar.send_keys('stephen king')\n",
    "\n",
    "\n",
    "bot = scraper()\n",
    "bot = scraper.click_search_bar()\n",
    "\n",
    "   '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%%\n",
    "\n",
    "from ast import Break\n",
    "from http.cookies import BaseCookie\n",
    "from typing import Container\n",
    "import selenium\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import chrome\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import re\n",
    "import uuid\n",
    "from uuid import UUID\n",
    "import os\n",
    "import json\n",
    "import urllib.request\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class scraper():\n",
    "\n",
    "    \"\"\" \n",
    "    This class is used to scrape good reads website\n",
    "\n",
    "    Attributes:\n",
    "    url (str): url of the webite. Here we have used goodreads\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self,book, url: str='https://www.goodreads.com/'):\n",
    "        self.book = book \n",
    "        self.driver = Chrome()\n",
    "        self.driver.get(url)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def click_search_bar(self, xpath: str = '//div[@class=\"auto_complete_field_wrapper\"]'):\n",
    "        \"\"\"\n",
    "        This function clicks the search bar on the webpage.\n",
    "\n",
    "        Args:\n",
    "            xpath (str): xpath of the search bar\n",
    "        \"\"\"\n",
    "        try:\n",
    "            WebDriverWait(self.driver,10).until(EC.presence_of_element_located((By.XPATH,xpath)))\n",
    "            self.driver.find_element(By.XPATH, xpath).click()\n",
    "            #self.driver.find_element(By.XPATH,xpath).send_keys('stephen king')\n",
    "            \n",
    "\n",
    "        except TimeoutException:\n",
    "            print(\"couldn't find search bar\")\n",
    "            \n",
    "\n",
    "\n",
    "    def search(self, xpath:str = '//input[@id=\"sitesearch_field\"]'):\n",
    "        \"\"\"\n",
    "        This function asks the user input on what to seach eg. book, author.\n",
    "\n",
    "        Args:\n",
    "            xpath (str): xpath of the search input\n",
    "        \"\"\"\n",
    "        try:\n",
    "            WebDriverWait(self.driver,10).until(EC.presence_of_element_located((By.XPATH,xpath)))\n",
    "            self.driver.find_element(By.XPATH,xpath).send_keys(input())\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(\"couldn't type the word in\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def click_search_button(self, xpath:str= '//*[@id=\"headerSearchForm\"]/a/img'): #'//img[@title=\"Title / Author / ISBN\"]'\n",
    "        \"\"\"\n",
    "        This function clicks the search button to start the searching.\n",
    "\n",
    "        Args:\n",
    "            xpath (str): xpath of the search button\n",
    "        \"\"\"\n",
    "        try:\n",
    "            WebDriverWait(self.driver,10).until(EC.presence_of_element_located((By.XPATH,xpath)))\n",
    "            self.driver.find_element(By.XPATH,xpath).click()\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(\"couldn't find the search button\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def close_login_popup(self, xpath:str= '//button[@class= \"gr-iconButton\"]'):\n",
    "        \"\"\"\n",
    "        This function refreshes the page to close the login pop-up.\n",
    "\n",
    "        Args:\n",
    "            xpath (str): xpath of the refresh button\n",
    "        \"\"\"\n",
    "        try:\n",
    "            #self.driver.switch_to.frame('//div[@id=\"overlay\"]')\n",
    "            WebDriverWait(self.driver,10).until(EC.presence_of_element_located((By.XPATH,xpath)))\n",
    "            self.driver.refresh()\n",
    "        \n",
    "        except TimeoutException:\n",
    "            print(\"no log-in pop up\")\n",
    "\n",
    "\n",
    "    def click_more_author(self, xpath:str= '/html/body/div[2]/div[3]/div[1]/div[2]/div[2]/table/tbody/tr[12]/td[2]/span[2]/div/a/span'): #//*[@id=\"description\"]/a\n",
    "\n",
    "        \"\"\"\n",
    "        This function clicks the click more button. This can be used to get the author details.\n",
    "\n",
    "        Args:\n",
    "            xpath (str): xpath of the click more button\n",
    "        \"\"\"\n",
    "\n",
    "        self.driver.find_element(By.XPATH,xpath).click()\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    def find_author_details(self, author = False, xpath: str ='a[@class = \"authorName\"]'):\n",
    "        \"\"\"\n",
    "        This function is used to the information about the author/author of the book we are searching.\n",
    "\n",
    "        Args:\n",
    "            author(bool): Here it is False\n",
    "            xpath (str) : xpath of the author name\n",
    "\n",
    "        Returns:\n",
    "            Dictionary: info_dict- with the information of the author.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            WebDriverWait(self.driver,10).until(EC.presence_of_element_located((By.XPATH,xpath)))\n",
    "\n",
    "            #author_cont = \n",
    "            \n",
    "            self.driver.find_element(By.XPATH,xpath).click()\n",
    "            #author_cont.self.diver.find_element()\n",
    "\n",
    "            author == True\n",
    "\n",
    "            \n",
    "        except TimeoutException:\n",
    "            print(\" author - time out\")\n",
    "            author == False\n",
    "\n",
    "        if author == True:\n",
    "            self.click_more_author()\n",
    "            author_details = self.driver.find_element(By.XPATH, '//*[@id=\"freeTextauthor5430144\"]')\n",
    "            info_dict['author details'].append(author_details.text)\n",
    "        else:\n",
    "            print('author details not found')\n",
    "\n",
    "        return info_dict\n",
    "    '''\n",
    "\n",
    "\n",
    "    def finding_containers(self, xpath:str= '//table[@class= \"tableList\"]'):\n",
    "        \"\"\"\n",
    "        This function finds the container which contains the links to all the book present in that page.\n",
    "\n",
    "        Args:\n",
    "            xpath (str): xpath of the container\n",
    "\n",
    "        Returns:\n",
    "            Container: which has the links\n",
    "        \"\"\"\n",
    "        global container\n",
    "        container = self.driver.find_element(By.XPATH,xpath)\n",
    "        return container\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def list_books_urls(self,x=True, xpath:str= '//tr'):\n",
    "        \"\"\"\n",
    "        This function uses the container obtained in the previous function to get all the book links needed.\n",
    "\n",
    "        Args:\n",
    "            xpath (str): xpath of the links\n",
    "        \"\"\"\n",
    "        global list_urls     \n",
    "        global list_books\n",
    "        global l\n",
    "\n",
    "        global info_dict\n",
    "        info_dict = {\n",
    "            'author details' :[],\n",
    "            'urls' :[],\n",
    "            'unique ID' :[],\n",
    "            'book title' :[],\n",
    "            'author name' :[],\n",
    "            'rating' :[],\n",
    "            'book description' :[],\n",
    "            'book_cover_links' :[],\n",
    "            'v4 UUID' :[]\n",
    "            }\n",
    "\n",
    "        #list_books=[]\n",
    "        \n",
    "\n",
    "        #ls = range(10)\n",
    "        #while n>10:\n",
    "        list_books = container.find_elements(By.XPATH, xpath)\n",
    "\n",
    "            #print(f'list of books is : {list_books}')\n",
    "            #list_books.append(lis_bk)\n",
    "\n",
    "        n = len(list_books)\n",
    "        print(f'the number of books url found are {n}')\n",
    "       # x=x+1\n",
    "        \n",
    "        for books in list_books:\n",
    "            list_urls.append(books.find_element(By.TAG_NAME, 'a').get_attribute('href'))\n",
    "\n",
    "        l=len(list_urls)\n",
    "\n",
    "        print(f'total number of books url found are {l}')\n",
    "\n",
    "        \n",
    "        \n",
    "            #if n==20:\n",
    "             #   self.next_page()\n",
    "              #  x==True\n",
    "               # list_books = None\n",
    "            #else:\n",
    "                #x==False\n",
    "             #   print('out of the while loop')\n",
    "\n",
    "        #print(list_urls)\n",
    "\n",
    "        '''\n",
    "        try:\n",
    "            WebDriverWait(self.driver,10).until(EC.presence_of_element_located((By.XPATH,xpath)))\n",
    "            list_books = self.containers.find_elements(By.XPATH, '//tr')\n",
    "            len(list_books)\n",
    "\n",
    "            \n",
    "            \n",
    "            for books in list_books:\n",
    "                list_urls.append(books.find_element(By.TAG_NAME, 'a').get_attribute('href'))\n",
    "\n",
    "        except TimeoutException:\n",
    "            print('cannot find the list urls')\n",
    "\n",
    "        '''\n",
    "        \n",
    "\n",
    "    def list_urls_other(self):\n",
    "\n",
    "        global list_urls\n",
    "        period=0\n",
    "\n",
    "        list_urls =[]\n",
    "        while period<7:\n",
    "            \n",
    "            self.finding_containers()\n",
    "            self.list_books_urls()\n",
    "            self.next_page()\n",
    "            if l>125:\n",
    "                #Break\n",
    "                print('out of the while loop')\n",
    "            else:\n",
    "                \n",
    "                print('contiues with while loop')\n",
    "            period+=1\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    def next_page(self,xpath:str='//div/a[@class=\"next_page\"]'):\n",
    "\n",
    "        try:\n",
    "            self.driver.find_element(By.XPATH,xpath).click()\n",
    "        except:\n",
    "            print('no next page available')\n",
    "\n",
    "    def book_title(self):\n",
    "\n",
    "        book_title = self.driver.find_element(By.XPATH, '//*[@id=\"bookTitle\"]')\n",
    "        info_dict['book title'].append(book_title.text)\n",
    "\n",
    "    def author_name(self):\n",
    "\n",
    "        author_name = self.driver.find_element(By.XPATH, '//*[@id=\"bookAuthors\"]')\n",
    "        info_dict['author name'].append(author_name.text)\n",
    "\n",
    "    def book_rating(self):\n",
    "\n",
    "        rating = self.driver.find_element(By.XPATH, '//*[@id=\"bookMeta\"]/span[2]')\n",
    "        info_dict['rating'].append(rating.text)\n",
    "\n",
    "\n",
    "    def book_des(self):\n",
    "\n",
    "        try:\n",
    "                self.click_more_book()\n",
    "                book_description = self.driver.find_element(By.XPATH, '//*[@id=\"descriptionContainer\"]')\n",
    "                info_dict['book description'].append(book_description.text)\n",
    "        except:\n",
    "                print('no book description available!')\n",
    "                book_description = 'no book description'\n",
    "\n",
    "    def image_link(self):\n",
    "\n",
    "        try:\n",
    "                image = self.driver.find_element(By.XPATH, '//*[@id=\"imagecol\"]/div[1]/div[1]/a')\n",
    "                imag_dic = image.find_element(By.TAG_NAME, 'img').get_attribute('src')\n",
    "        except:\n",
    "                print('no book cover found for this book')\n",
    "                imag_dic = 'no book cover'\n",
    "        info_dict['book_cover_links'].append(imag_dic)\n",
    "\n",
    "    def uuid_id(self):\n",
    "\n",
    "        uu_id = uuid.uuid4()\n",
    "        uuid_str = str(uu_id)\n",
    "        info_dict['v4 UUID'].append(uuid_str)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def click_more_book(self, xpath:str= '//*[@id=\"description\"]/a'): #\n",
    "        \"\"\"\n",
    "        This function clicks the click more button. This can be used to get the full book description.\n",
    "        Args:\n",
    "            xpath (str): xpath of the click more button\n",
    "        \"\"\"\n",
    "\n",
    "        self.driver.find_element(By.XPATH,xpath).click()\n",
    "\n",
    "    @staticmethod\n",
    "    def save_injson():\n",
    "\n",
    "        \"\"\"\n",
    "        This function used to create a json file in a new folder \n",
    "        and add the informations found in the previous function.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        folder = r'raw_data'\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "\n",
    "        with open(\"/home/pramika/Documents/Aicore/data_collection_project/raw_data/data.json\", \"w+\") as f:\n",
    "            json.dump(info_dict, f)\n",
    "\n",
    "\n",
    "    '''\n",
    "    def saving_images(self):\n",
    "\n",
    "        folder = r'/home/pramika/Documents/Aicore/data_collection_project/raw_data/images'\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def download_images():\n",
    "        \"\"\"\n",
    "        This function downloads the book cover using the links found in the \n",
    "        book_info function. The book covers are stored in a folder named images.\n",
    "\n",
    "        \"\"\"\n",
    "        folder = r'/home/pramika/Documents/Aicore/data_collection_project/raw_data/images'\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "\n",
    "        book_links = info_dict[\"book_cover_links\"]\n",
    "        #print(book_links)\n",
    "\n",
    "        for i,lst in enumerate(book_links):\n",
    "            try:\n",
    "                driver.get(lst)\n",
    "                urllib.request.urlretrieve(lst,f'/home/pramika/Documents/Aicore/data_collection_project/raw_data/images/{bot.book}{i}.jpg')\n",
    "            except:\n",
    "                print('no book cover available')\n",
    "\n",
    "\n",
    "\n",
    "class bookscraper(scraper):\n",
    "    def __init__(self):\n",
    "        self.books='books'\n",
    "\n",
    "    def books_info(self):\n",
    "        \"\"\"\n",
    "        This function uses the book links found in the previous \n",
    "        function to get information about the book such as urls,\n",
    "        book name, author name, ratings, book descriptions and \n",
    "        book cover links. Here we are also creating a UUID for\n",
    "        each book and also finding the unique id for each link.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        #global info_dict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        for urls in list_urls[0:l]:\n",
    "\n",
    "            self.driver.get(urls)\n",
    "            info_dict['urls'].append(urls)\n",
    "\n",
    "\n",
    "            ur = re.findall('\\d+', urls)\n",
    "            info_dict['unique ID'].append(ur[0])\n",
    "\n",
    "               \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "            #self.driver.get(urls)\n",
    "            #print(f'image is {image}')\n",
    "            #print( f'imag dic {imag_dic}')\n",
    "            #print(image)\n",
    "            #img= image.get_attribute('src')\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            #return info_dict\n",
    "\n",
    "        #print(info_dict)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    bot = scraper('Colleen Hoover')\n",
    "    bot.click_search_bar()\n",
    "    bot.search()\n",
    "    bot.click_search_button()\n",
    "    bot.close_login_popup()\n",
    "    #bot.click_more_author()\n",
    "    #bot.find_author_details()\n",
    "    #bot.finding_containers()\n",
    "    #bot.list_books_urls()\n",
    "    bot.list_urls_other()\n",
    "    #bot.next_page()\n",
    "    bot.books_info()\n",
    "    #bot.click_more_book()\n",
    "    bot.save_injson()\n",
    "    bot.download_images()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
